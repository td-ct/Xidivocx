{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwxmUhxgBOR-"
   },
   "source": [
    "# Application of machine learning concepts on lung X-rays to indicate COVID-19\n",
    "\n",
    "In this project we will build and train a neural network in Tensorflow. \n",
    "- more details\n",
    "- Dataset: [Public X-rays on Github](https://github.com/ieee8023/covid-chestxray-dataset)\n",
    "- Waterkant Dataset: [CAU cloud as zip](https://cloud.physik.uni-kiel.de/index.php/s/aLDok2nyDawrHnE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaKEJ7djcfPM"
   },
   "source": [
    "#TO DO LIST\n",
    "- Preprocess the images: Make them all purely grayscale (and mark them for potential problems) <font color=\"purple\"> $\\boxed{\\checkmark}$ TD </font>\n",
    "- Brightness augmentations <font color=\"green\"> $\\boxed{\\checkmark}$ VD </font>\n",
    "- Noise/Interference augmentations\n",
    "- In-Process plots to monitor the learning and source data plots <font color=\"green\"> $\\boxed{\\checkmark}$ VD </font>\n",
    "- Data evaluation plots to spot possible overfitting or other issues <font color=\"green\"> $\\boxed{\\checkmark}$ VD </font>\n",
    "- Including a git-pull instead of resetting every time <font color=\"purple\"> $\\boxed{\\checkmark}$ TD </font>\n",
    "- Create automatic steps per epoch integer<font color=\"green\"> $\\boxed{\\checkmark}$ VD </font>\n",
    "- Add confusion matrix\n",
    "<font color=\"blue\"> $\\boxed{\\checkmark}$ KK </font>\n",
    "- Add upload field for testing unclassified images from extern\n",
    "<font color=\"blue\"> $\\boxed{\\checkmark}$ KK </font>\n",
    "- Add imread from 2 class source for KFStratified\n",
    "<font color=\"blue\"> $\\boxed{\\checkmark}$ KK </font>\n",
    "- Add model.evaluation\n",
    "- Add regular expressions to data management, to anticipate slightly misslabeled entries\n",
    "- Include a pre-trained neural network VGG16, see http://www.robots.ox.ac.uk/~vgg/research/very_deep/<font color=\"green\"> $\\boxed{\\checkmark}$ VD </font>\n",
    "- Include more pre-trained NNs as alternative, e.g. ResNet50 from Keras https://engmrk.com/kerasapplication-pre-trained-model/?utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com <font color=\"purple\"> $\\boxed{\\checkmark}$ TD </font>\n",
    "- Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRvsEYHoDz4I"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3c2v2gqeBNN9",
    "outputId": "07b63e01-d308-491b-d97e-6f2214af7a9b"
   },
   "outputs": [],
   "source": [
    "#Basics\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "#Google\n",
    "from google.colab import drive\n",
    "\n",
    "#Neural Network related\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Pretrained Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#Displaying\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "#KF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2I5teKcMFR9B"
   },
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-gSLHG4oJZKm"
   },
   "source": [
    "### Connecting to the Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "z0ZzOL6YJiN3",
    "outputId": "6c77651f-56be-4184-841f-7aea5f471328"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4wKEqCRI2Nk"
   },
   "source": [
    "### Downloading the first dataset containing training, testing and an unlabeled validation dataset (D10zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "Ex8VZsy4IznD",
    "outputId": "c93971af-53f0-4347-e908-6bcd80805ac4"
   },
   "outputs": [],
   "source": [
    "!curl -o D10.zip -L https://cloud.physik.uni-kiel.de/index.php/s/aLDok2nyDawrHnE/download\n",
    "#Clean up directory\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('/content/chest_xray')\n",
    "    print(\"Base directory was successfully cleaned\")\n",
    "except OSError as error:\n",
    "    print(\"Dont need to clean if there is nothing to clean\")\n",
    "\n",
    "\n",
    "#Entpacken\n",
    "local_zip = '/content/D10.zip'\n",
    "print(os.path.getsize(local_zip)) \n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/content/chest_xray')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the second dataset containing the additional validation dataset \"MIX.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "Diww1inJhTRE",
    "outputId": "1649beae-7c55-4653-8b94-1423541e343b"
   },
   "outputs": [],
   "source": [
    "prediction_dir_2 = os.path.join(base_dir, 'prediction2')\n",
    "\n",
    "dir_list =[prediction_dir_2]\n",
    "\n",
    "for entry in dir_list:\n",
    "    try: \n",
    "        os.makedirs(entry, exist_ok = True) \n",
    "        print(\"Directory '%s' was created successfully\" %entry) \n",
    "    except OSError as error: \n",
    "        print(\"Directory '%s' can not be created\" %entry) \n",
    "\n",
    "!curl -o MIX.zip -L https://cloud.physik.uni-kiel.de/index.php/s/mAYD278NrifpkQo/download\n",
    "\n",
    "local_zip = '/content/MIX.zip'\n",
    "print(os.path.getsize(local_zip)) \n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/content/chest_xray/MIX')\n",
    "zip_ref.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FoyU3SEIym8"
   },
   "source": [
    "### Defining output directory variables fitting to the downloaded dataset and create them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "ckNoMFyTFbKl",
    "outputId": "dc4bb5c4-fd8b-48fd-ccc8-4b3879b2f40b"
   },
   "outputs": [],
   "source": [
    "base_inputdata_dir = '/content/chest_xray/chest_xray'\n",
    "\n",
    "waterkant20_train         = base_inputdata_dir+'/train'  #training data in two groups\n",
    "waterkant20_train_covid   = waterkant20_train+'/PNEUMONIA'    \n",
    "waterkant20_train_nocovid = waterkant20_train+'/NORMAL'\n",
    "\n",
    "waterkant20_val           = base_inputdata_dir+'/val'    #validation data during training in two groups\n",
    "waterkant20_val_covid     = waterkant20_val+'/PNEUMONIA'\n",
    "waterkant20_val_nocovid   = waterkant20_val+'/NORMAL'\n",
    "\n",
    "waterkant20_test  = base_inputdata_dir+'/test'           #final mixed test data not cliassified so far\n",
    "waterkant20_test_mix = waterkant20_test+'/MIX'           # <=== Let's sort it!!!\n",
    "\n",
    "#Checking contents\n",
    "waterkant20_path_list=[waterkant20_train_covid,waterkant20_val_covid,waterkant20_train_nocovid,waterkant20_val_nocovid,waterkant20_test_mix]\n",
    "\n",
    "for path in waterkant20_path_list:\n",
    "  print(str(len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]))+\" files in \"+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eG0XT45lKr5Y"
   },
   "source": [
    "### Creating output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "hOJya68yKwln",
    "outputId": "5f255d2f-e98b-4b0f-9f58-a4e2d43551a0"
   },
   "outputs": [],
   "source": [
    "#Cleanup\n",
    "try:\n",
    "    shutil.rmtree('/content/gdrive/My Drive/Deep_Learning_Project/Data')\n",
    "    print(\"Base directory was successfully cleaned\")\n",
    "except OSError as error:\n",
    "    print(\"Dont need to clean if there is nothing to clean\")\n",
    "\n",
    "\n",
    "#Base directory for monochromized files before feeding to Training/Testing and Prediction\n",
    "base_dir             = '/content/gdrive/My Drive/Deep_Learning_Project/Data'\n",
    "\n",
    "training_dir         = os.path.join(base_dir, 'training')\n",
    "training_covid_dir   = os.path.join(training_dir, 'covid')\n",
    "training_nocovid_dir = os.path.join(training_dir, 'nocovid')\n",
    "\n",
    "testing_dir          = os.path.join(base_dir, 'testing')\n",
    "testing_covid_dir    = os.path.join(testing_dir, 'covid')\n",
    "testing_nocovid_dir  = os.path.join(testing_dir, 'nocovid')\n",
    "\n",
    "prediction_dir   = os.path.join(base_dir, 'prediction') #First unlabeled datset for prediction\n",
    "prediction_dir_2 = os.path.join(base_dir, 'prediction2') #Second unlabeled datset for prediction\n",
    "\n",
    "#Not needed for Waterkant dataset - final cleanup will sort this | VD\n",
    "#source_covid = os.path.join(base_dir, 'source_covid')\n",
    "#source_nocovid = os.path.join(base_dir, 'source_nocovid')\n",
    "\n",
    "dir_list = [training_covid_dir, training_nocovid_dir, testing_covid_dir, testing_nocovid_dir, prediction_dir] #source_covid, source_nocovid \n",
    "\n",
    "for entry in dir_list:\n",
    "    try: \n",
    "        os.makedirs(entry, exist_ok = True) \n",
    "        print(\"Directory '%s' was created successfully\" %entry) \n",
    "    except OSError as error: \n",
    "        print(\"Directory '%s' can not be created\" %entry) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SiykA3FP_Gw"
   },
   "source": [
    "### Monochromize and distribute data to the corresponding directories\n",
    "The function monochromize(img) can monochromize (numpy)images. \n",
    "The function copyFileMonochromized uses monochromize() and in addition the output filename is expanded by keywords to reflect, if their input image:\n",
    "*   did not have a dpi setting\n",
    "*   did actually have color, expressed as with mean and max \"color\"-values\n",
    "\n",
    "Some aspects could have been reflected by the .convert(\"L\") function in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBCFTf_zPECN"
   },
   "outputs": [],
   "source": [
    "#TD: monochromize the data! Using numpy slice operations: https://www.w3schools.com/python/numpy_array_slicing.asp\n",
    "#TD: Using e ITU-R 601-2 luma transform: L = R * 299/1000 + G * 587/1000 + B * 114/1000, it does not affect already grayscale images saved as RGB...\n",
    "\n",
    "#Reduces RGB and RGBA to monochrome numpy array\n",
    "def monochromize(img): \n",
    "  if (img.ndim==2): \n",
    "    return img                                      #monochrome\n",
    "  if (img.ndim==3):\n",
    "    channels = img.shape[2]\n",
    "    if (channels==3):\n",
    "      return (img[:,:,0]*0.299+img[:,:,1]*0.587+img[:,:,2]*0.114).astype(int) #RGB\n",
    "    if (channels==4):\n",
    "      return (img[:,:,0]*0.299+img[:,:,1]*0.587+img[:,:,2]*0.114).astype(int) #RGBA - no usage of alpha channel\n",
    "  print(\"image is neither of type monochrome,RGB or RGBA. Contact the dataset provider.\")\n",
    "  return img                                   \n",
    "\n",
    "\n",
    "#TD: Apply monochromize while copying the file from path_in to path_out\n",
    "def copyfileMonochromized(img_path_in,img_path_out):\n",
    "    im = Image.open(img_path_in,mode=\"r\")\n",
    "    img = np.asarray(im)\n",
    "    \n",
    "    #Additional info endings to file\n",
    "    t = \".tif\"\n",
    "    m = \"_monochromized\"\n",
    "\n",
    "    #check for color!\n",
    "    c = \"\"\n",
    "    if (img.ndim==3): #not monochrome\n",
    "        if not (np.count_nonzero(img[:,:,0]-img[:,:,1])==0 and np.count_nonzero(img[:,:,0]-img[:,:,2])==0 and np.count_nonzero(img[:,:,1]-img[:,:,2])==0):\n",
    "            mean = int(round((np.average(np.abs(img[:,:,0].astype(int)-img[:,:,1])) + np.average(np.abs(img[:,:,0].astype(int)-img[:,:,2])) + np.average(np.abs(img[:,:,1].astype(int)-img[:,:,2])))/3.0))\n",
    "            maxi = np.amax([np.amax(np.abs(img[:,:,0].astype(int)-img[:,:,1])),np.amax(np.abs(img[:,:,0].astype(int)-img[:,:,2])),np.amax(np.abs(img[:,:,1].astype(int)-img[:,:,2]))])\n",
    "            c = \"_hadcolor_\"+str(mean)+\"_\"+str(maxi)\n",
    "\n",
    "    d = \"_nodpi\"\n",
    "    img = monochromize(img)\n",
    "    im2 = Image.fromarray(np.uint8(img))\n",
    "    dpi = im.info.get('dpi')\n",
    "    if dpi is None: #no dpi setting\n",
    "        im2.save(img_path_out+c+d+m+t)\n",
    "    else:\n",
    "      dpi_x,dpi_y = dpi\n",
    "      im2.save(img_path_out+c+m+t,resolution_unit=\"inch\", x_resolution=dpi_x, y_resolution=dpi_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_Iy3cc4XERX"
   },
   "source": [
    "### Copy first dataset into corresponding directories while monochromizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "nSNNwQOjf-7p",
    "outputId": "ec54f287-25c6-40eb-9283-e365c70d3e9e"
   },
   "outputs": [],
   "source": [
    "# Tuple list of directories with [source, destination] layout\n",
    "waterkant20_src_dest_list=[[waterkant20_train_covid,training_covid_dir],\n",
    "                           [waterkant20_val_covid,testing_covid_dir],\n",
    "                           [waterkant20_train_nocovid,training_nocovid_dir],\n",
    "                           [waterkant20_val_nocovid,testing_nocovid_dir],\n",
    "                           [waterkant20_test_mix,prediction_dir]]\n",
    "                           \n",
    "for src,dest in waterkant20_src_dest_list:\n",
    "  print(\"Copy \"+src+\" to \"+dest)\n",
    "  src_files = os.listdir(src)\n",
    "  for file_name in src_files:\n",
    "    full_file_src = os.path.join(src, file_name)\n",
    "    full_file_dest = os.path.join(dest,file_name)\n",
    "    if os.path.isfile(full_file_src):\n",
    "        #shutil.copy(full_file_name, dest)\n",
    "        copyfileMonochromized(full_file_src,full_file_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy second dataset into corresponding directories while monochromizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YgwazZ8ciq4y",
    "outputId": "88802cb9-e9ab-4c85-9319-361aba5e7827"
   },
   "outputs": [],
   "source": [
    "# Tuple list of directories with [source, destination] layout\n",
    "waterkant20_test_mix_2 = '/content/chest_xray/MIX'\n",
    "\n",
    "waterkant20_src_dest_list=[[waterkant20_test_mix_2,prediction_dir_2]]\n",
    "                           \n",
    "for src,dest in waterkant20_src_dest_list:\n",
    "  print(\"Copy \"+src+\" to \"+dest)\n",
    "  src_files = os.listdir(src)\n",
    "  for file_name in src_files:\n",
    "    full_file_src = os.path.join(src, file_name)\n",
    "    full_file_dest = os.path.join(dest,file_name)\n",
    "    if os.path.isfile(full_file_src):\n",
    "        #shutil.copy(full_file_name, dest)\n",
    "        copyfileMonochromized(full_file_src,full_file_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking contents after copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "z-tRSety7beU",
    "outputId": "39ee4529-371e-4691-bdac-ed25f3e5efb2"
   },
   "outputs": [],
   "source": [
    "waterkant20_path_list2=[training_covid_dir,testing_covid_dir,training_nocovid_dir,testing_nocovid_dir,prediction_dir]\n",
    "\n",
    "for path in waterkant20_path_list2:\n",
    "  print(str(len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]))+\" files in \"+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0n2UepA5w0a"
   },
   "source": [
    "# Data Retrieval by ImageDataGenerator\n",
    "- Setting up the ImageDataGenerators for training and testing\n",
    "- in the training case with some augmentations\n",
    "- set image size to 324 x 324 in the flow_from_directory method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C0t0MeTu55wf",
    "outputId": "6502c29d-42a5-4d86-8ae6-4b97a25cbf39"
   },
   "outputs": [],
   "source": [
    "#Setting up the generators and creating and instance of it\n",
    "#Hyperparameters\n",
    "batch_size_training = 32\n",
    "batch_size_testing = 4\n",
    "\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                      rotation_range=10,\n",
    "                                      zoom_range=0.1,\n",
    "                                      brightness_range=[0.7,1.3],\n",
    "                                      horizontal_flip=True,\n",
    "                                      #vertical_flip=True,  #Not happening in our data\n",
    "                                      fill_mode='nearest'\n",
    "                                      )\n",
    "\n",
    "testing_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(training_dir,\n",
    "                                                         batch_size=batch_size_training,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (324, 324))\n",
    "\n",
    "testing_generator = testing_datagen.flow_from_directory(testing_dir,\n",
    "                                                    batch_size=batch_size_testing,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(324, 324))\n",
    "\n",
    "\n",
    "#Expected output training:   5216, 2 classes\n",
    "#Expected output validation: 16,   2 classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9VKsggIAgMt"
   },
   "source": [
    "## Creating the Neural network \n",
    "- Based on pretrained model(VGG16)\n",
    "- Exit at block3_pool layer of the VGG16 to keep a certain minimum shape to still work with\n",
    "- A not untrained model can be found in the Appendix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LZPt_-_Pj3hk",
    "outputId": "060d6d19-29bd-4c48-f71d-b31c58131642"
   },
   "outputs": [],
   "source": [
    "#Create an instance of the pretrained model\n",
    "\n",
    "#Setting up some Hyperparameters\n",
    "pre_trained_setup = \"VGG16\" #\"ResNet50\"  #Hyperparameter to change bewteen the pretrained models\n",
    "lr = 0.0015 # Learning rate # Adjusted by VD on 3.6.2020\n",
    "dr_0 = 0.65 # Dropout rate for first layer it appears in\n",
    "dr_1 = 0.6 # Dropout rate for second layer it appears in\n",
    "\n",
    "if (pre_trained_setup == \"VGG16\"):\n",
    "    print(\"Using VGG16\")\n",
    "    pre_trained_model = VGG16(input_shape = (324, 324, 3), \n",
    "                              include_top = False, \n",
    "                              weights = \"imagenet\") # We can consider other weights too! VD see http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "if (pre_trained_setup == \"ResNet50\"):\n",
    "    print(\"Using ResNet50\")\n",
    "    pre_trained_model = ResNet50(input_shape = (324, 324, 3), \n",
    "                                 include_top = False, \n",
    "                                 weights = \"imagenet\")\n",
    "\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "  \n",
    " # Print the model summary if you want further infos\n",
    " # print(pre_trained_model.summary())\n",
    "\n",
    "#TD selectiong between VGG16 and ResNet50\n",
    "#Choosing a \"exit\"-layer from the pretrained to further use the selfmodeled one\n",
    "if (pre_trained_setup == \"VGG16\"):\n",
    "  #last_layer = pre_trained_model.get_layer('block3_pool') # 40, 40, 256 =>  40, 40, 512\n",
    "  last_layer = pre_trained_model.get_layer('block2_pool') # 80, 80\n",
    "  #last_layer = pre_trained_model.get_layer('block4_pool') # 40, 40\n",
    "if (pre_trained_setup == \"ResNet50\"):\n",
    "  last_layer = pre_trained_model.get_layer('conv3_block2_add') # 41, 41, 512 => 41, 41, 512\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "\n",
    "# Add costum layers after the pretrained model for specific purposes\n",
    "output = layers.Conv2D(32, (3,3), activation='relu')(last_output)\n",
    "output = layers.AveragePooling2D(2,2)(output)\n",
    "output = layers.Conv2D(64, (3,3), activation='relu')(output)\n",
    "output = layers.MaxPooling2D(2,2)(output)\n",
    "output = layers.Dropout(dr_0)(output)\n",
    "output = layers.Conv2D(128, (3,3), activation='relu')(output)\n",
    "output = layers.MaxPooling2D(2,2)(output)\n",
    "output = layers.Flatten()(output) \n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "output = layers.Dropout(dr_1)(output) \n",
    "output = layers.Dense(1, activation='sigmoid')(output) \n",
    "\n",
    "# Create a instance of the model in the desired layout\n",
    "model = Model( pre_trained_model.input, output)   \n",
    "\n",
    "#Compile it!\n",
    "model.compile(optimizer = Adam(learning_rate=lr), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "#Setup a Callback to not overcomputate\n",
    "early_stopping_monitor = tf.keras.callbacks.EarlyStopping(patience = 3, monitor = \"acc\", mode=\"max\", verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scbS_xBWEd4s"
   },
   "source": [
    "## Train the model on our training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "zP4U3iSTfQt0",
    "outputId": "6a0ddc19-8a05-46bf-b5ff-3ae6e2131932"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit_generator(training_generator,\n",
    "                              epochs=epochs,\n",
    "                              steps_per_epoch=int((len(os.listdir(training_covid_dir))+len(os.listdir(training_nocovid_dir)))/batch_size_training),\n",
    "                              validation_data=testing_generator,\n",
    "                              verbose = 1,\n",
    "                              validation_steps=int((len(os.listdir(testing_covid_dir))+len(os.listdir(testing_nocovid_dir)))/batch_size_testing),\n",
    "                              callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhdFBvm2t_P-"
   },
   "source": [
    "## Prediction and Result generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the unlabeled evaluation datasets and generate json result file for the Waterkant Hackathon 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sehJrOKPuIBz",
    "outputId": "977dbbfe-5e2b-48a1-baf7-31a1e42bf4bb"
   },
   "outputs": [],
   "source": [
    "#\n",
    "waterkant_prediction_list = os.listdir(prediction_dir_2)\n",
    "nrlab = []\n",
    "low=0;\n",
    "hi=0;\n",
    "\n",
    "for filename in waterkant_prediction_list:\n",
    "  # predicting images\n",
    "  path = prediction_dir_2 + '/' + filename\n",
    "  img=image.load_img(path, target_size=(324, 324))\n",
    "  \n",
    "  x=image.img_to_array(img)\n",
    "  x=np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    "  \n",
    "  classes = model.predict(images, batch_size=100)\n",
    "\n",
    "  nr = (re.match(r\"^([^.]*)\\..*$\",filename)).group(1)\n",
    "  lab = classes[0]\n",
    "  c = int(round(lab[0]))\n",
    "  nrlab.append([int(nr),c]) #TD sigmoid from -inf..inf spans 0..1, cut at 0.5\n",
    "\n",
    "#  print(lab)\n",
    "  if c == 1:\n",
    "    hi += 1\n",
    "#    print(filename + \" is not covid\")\n",
    "  else:\n",
    "    low +=1\n",
    "#    print(filename + \" is covid\")\n",
    "\n",
    "\n",
    "print(\"Distribution: \"+str(hi)+\" High and \"+str(low)\n",
    "\n",
    "#nrlab.sort(key=lambda tup: tup[0])\n",
    "L = [\"[\\n\"]  \n",
    "for n,l in nrlab:\n",
    "  L.append('  {\"image\": \"'+str(n)+'.jpg\", \"prediction\": '+str(l)+'},\\n')\n",
    "L[len(L)-1] = L[len(L)-1][:-2]+\"\\n\"\n",
    "L.append(\"]\\n\")\n",
    "file1 = open('covid-'+datetime.now().strftime('%Y%m%d%H%M%S')+'.json',\"w\")\n",
    "file1.writelines(L)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYhN6qjQ8Qg6"
   },
   "source": [
    "# KFStratified wrap around CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Tx2FpZ9A3Hv2",
    "outputId": "2d33a4aa-c5b4-490e-985a-888337767724"
   },
   "outputs": [],
   "source": [
    "## KK imread from 2 class source for KFStratified\n",
    "\n",
    "CATEGORIES = [\"source_covid\", \"source_nocovid\"]\n",
    "\n",
    "IMG_SIZE = 324\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "\n",
    "        path = os.path.join(base_dir,category)  # create path to covid noncovid\n",
    "        class_num = CATEGORIES.index(category)  # get the classification 0 or 1\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image covid noncovid\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()\n",
    "print(len(training_data))\n",
    "\n",
    "# shuffle the sorted readed images from folder ...00000... , ...11111...\n",
    "random.shuffle(training_data)\n",
    "\n",
    "#TD try numpy instead of = []\n",
    "#IMAGES = np.array() #image\n",
    "#LABELS = np.array() #label\n",
    "# split in X and y\n",
    "#for features,label in training_data:\n",
    "#    np.append(IMAGES,features)\n",
    "#    np.append(LABELS,label)\n",
    "\n",
    "#TD try numpy instead\n",
    "IMAGES = [] #image\n",
    "LABELS = [] #label\n",
    "# split in X and y\n",
    "for features,label in training_data:\n",
    "    IMAGES.append(features)\n",
    "    LABELS.append(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reshape for cnn\n",
    "IMAGES = np.array(IMAGES).reshape(-1, IMG_SIZE, IMG_SIZE, 1) #1=grayscale\n",
    "LABELS = np.array(LABELS)\n",
    "\n",
    "# normalize data between 0 and 1\n",
    "IMAGES = IMAGES/255.0\n",
    "np.shape(IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "eCgXtcxg8ME1",
    "outputId": "64f26683-309d-4e75-d77e-988d8320068b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "#TEST ARRAYS\n",
    "XX = [(22,22),(333,333),(55,55),(44,44),(666,666),(88,666),(889,666),(9,666),(9000,666)]\n",
    "yy = [0,0,0,0,1,1,1,0,2]\n",
    "\n",
    "XX = np.array(XX)\n",
    "yy = np.array(yy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function confusion matrix\n",
    "def plot_cm(y_true, y_pred, figsize=(6,6)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual / True'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "# function for set up all classes to equal\n",
    "def balance2D_minority_class(x_in, y_in):\n",
    "    #org_shape = x_in.shape\n",
    "    #vol_shape = x_in.shape[1:]\n",
    "    #n_voxels = np.prod(vol_shape)\n",
    "     \n",
    "    #images_by_voxel = x_in.reshape((x_in.shape[0], n_voxels), order='C')\n",
    "    \n",
    "    ros = RandomOverSampler(sampling_strategy='not majority', random_state=12, return_indices=True)\n",
    "    x_in, y_in, idx = ros.fit_sample(x_in, y_in)#(images_by_voxel, y_in)\n",
    "    print('Oversample indexes:', idx)\n",
    "\n",
    "    x_in, y_in = shuffle(x_in, y_in, random_state=12)\n",
    "    \n",
    "    #x_in = x_in.reshape(x_in.shape[0], *vol_shape)\n",
    "      \n",
    "    return x_in, y_in\n",
    "\n",
    "\n",
    "# things for SKF\n",
    "N_SPLITS = 3\n",
    "\n",
    "# things for CNN\n",
    "EPOCHS = 400\n",
    "STEP_PER_EPOCH = 120\n",
    "BATCH_SIZE = 3#5\n",
    "\n",
    "# clear model in memory\n",
    "model = None\n",
    "\n",
    "# set crossvalidation iterator\n",
    "SKF = StratifiedKFold(n_splits = N_SPLITS, shuffle=True, random_state=12)\n",
    "\n",
    "for index_fold, (train_index, test_index) in enumerate(SKF.split(XX, yy)):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print('\\n--------NEW RUN---------\\n')\n",
    "   \n",
    "    RUN = \"training on fold \" + str(index_fold+1) + \"-\" + str(N_SPLITS)\n",
    "    print (RUN, '\\n')\n",
    "    #break\n",
    "    # get the indeces\n",
    "    \n",
    "    print(IMAGES[0].shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = XX[train_index], XX[test_index], yy[train_index], yy[test_index]\n",
    "    \n",
    "    print('KFold_Train: ', y_train, '\\nKFold_Test: ', y_test, '\\n')\n",
    "    \n",
    "    # reshape, balancing by resampling minority classes reshape, shuffle\n",
    "    X_train, y_train = balance2D_minority_class(X_train, y_train)\n",
    "    print('Balance_shuffle_train: ', y_train, '\\nTest: ', y_test, '\\n')\n",
    "\n",
    "    break\n",
    "\n",
    "    # skf.split cant handle 1hot-encoding ... but we need it for cnn\n",
    "    y_train = np.array(to_categorical(y_train), dtype='uint8')\n",
    "    y_test = np.array(to_categorical(y_test), dtype='uint8')\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------\n",
    "    \n",
    "    look_X_train.append(X_train)\n",
    "    look_X_test.append(X_test)\n",
    "    look_y_train.append(y_train)\n",
    "    #look_y_test.append(y_test)\n",
    "       \n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # clear model\n",
    "    model = None\n",
    "\n",
    "    # SET THE MODEL HERE in code or pick the define model \n",
    "    #model = cnn1(input_shape)\n",
    "\n",
    "      \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = Adam(lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                                  steps_per_epoch=STEP_PER_EPOCH,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  verbose=2)\n",
    "    \n",
    "    # prediction\n",
    "    pred_class = model.predict(X_test)\n",
    "    y_predict_class = np.argmax(pred_class, axis=1)\n",
    "    \n",
    "    #save predictions on y_test\n",
    "    look_y_pred.append(y_predict_class)\n",
    "    \n",
    "    # redo 1-hot-encoding\n",
    "    y_test_redo_1hot = [np.where(r==1)[0][0] for r in y_test]\n",
    "    \n",
    "    # save y_test classes\n",
    "    look_y_test.append(y_test_redo_1hot)\n",
    "    \n",
    "    # get values outside this loop for global confusion matrix / statistics\n",
    "    n_splits_scores.append(accuracy_score(y_test_redo_1hot, y_predict_class))\n",
    "    n_splits_y_test = np.concatenate((n_splits_y_test, y_test_redo_1hot))\n",
    "    n_splits_y_pred = np.concatenate((n_splits_y_pred, y_predict_class))\n",
    "\n",
    "\n",
    "    # ready to plot\n",
    "    #plot_cm(y_true, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "aA5iDDtV02vE",
    "outputId": "4815ec92-4189-4799-ece0-849c1bec5c66"
   },
   "outputs": [],
   "source": [
    "TD1 = np.array([1,2,3,44,5,6,7])\n",
    "INDEX1 = np.array([3,4,5])\n",
    "print(TD1[INDEX1])\n",
    "\n",
    "print(np.append(TD1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCCdDdEjGZs-"
   },
   "source": [
    "# prediction / evaluation (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "_1SNA2Bb4DO6",
    "outputId": "9644f778-70ac-46bf-ab15-d089667bfcfc"
   },
   "outputs": [],
   "source": [
    "## KK\n",
    "\n",
    "# get prediction from testing_generator with testdata length\n",
    "predict = model.predict_generator(testing_generator, steps=len(testing_dir))\n",
    "#print(predict)\n",
    "\n",
    "#Y_pred = predict > 0.5\n",
    "#print(Y_pred)\n",
    "\n",
    "y_pred = np.argmax(predict, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "# get true class value from testdata\n",
    "y_true = testing_generator.classes\n",
    "#print(y_true)\n",
    "\n",
    "\n",
    "# function confusion matrix\n",
    "def plot_cm(y_true, y_pred, figsize=(6,6)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual / True'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n",
    "\n",
    "# ready to plot\n",
    "plot_cm(y_true, y_pred)\n",
    "\n",
    "#confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAcM43Te4_sE"
   },
   "source": [
    "# Load image from extern to run trough CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 58,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "z1g88PIG5K9y",
    "outputId": "544e8fe2-6ba9-4937-c6d7-88a755799767"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(324, 324))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" Covid_19\")\n",
    "  else:\n",
    "    print(fn + \" NO Covid-19\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGl8wp3u_Thl"
   },
   "source": [
    "# Loading plot library and displaying some images from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "id": "I0RkzNx-_gV4",
    "outputId": "cc1d547a-d971-45c0-d658-2d32aa2f26b9"
   },
   "outputs": [],
   "source": [
    "## KK imports nach oben verlagert\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "\n",
    "# Grid parameters for display\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "#Create a list with the filenames for the iteration\n",
    "training_covid_names = os.listdir(training_covid_dir)\n",
    "training_nocovid_names = os.listdir(training_nocovid_dir)\n",
    "\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_covid_pix = [os.path.join(training_covid_dir, fname) \n",
    "                for fname in training_covid_names[pic_index-8:pic_index]]\n",
    "next_nocovid_pix = [os.path.join(training_nocovid_dir, fname) \n",
    "                for fname in training_nocovid_names[pic_index-8:pic_index]]\n",
    "\n",
    "\n",
    "#TD now with filenames in the headlines...\n",
    "fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(16, 16))\n",
    "for ax,img_path in zip(axs.flat,next_covid_pix+next_nocovid_pix):\n",
    "    fname = re.sub('^.*[\\/\\\\\\\\]','',img_path)\n",
    "    img = mpimg.imread(img_path)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(str(fname),fontsize=7)\n",
    "plt.show()\n",
    "\n",
    "#for i, img_path in enumerate(next_covid_pix+next_nocovid_pix):\n",
    "#  # Set up subplot; subplot indices start at 1\n",
    "#  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "#  #sp.axis('Off') # Don't show axes (or gridlines)\n",
    "#\n",
    "#  img = mpimg.imread(img_path)\n",
    "#TD: Set \",cmap=\"gray\" \" here (refer to https://matplotlib.org/3.2.1/tutorials/colors/colormaps.html) but also preprocess the incoming data in monochromize()\n",
    "#  plt.imshow(img,cmap=\"gray\")\n",
    "#\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T--4hwPeCb-Q"
   },
   "source": [
    "#Display intermediate steps to see the model working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hUV4mRT6Chq9",
    "outputId": "68182843-c138-4262-9418-edecf0e3111c"
   },
   "outputs": [],
   "source": [
    "# This will take an image as input, and will output\n",
    "# intermediate representations for all layers in the given model\n",
    "\n",
    "training_covid_names = os.listdir(training_covid_dir)\n",
    "training_nocovid_names = os.listdir(training_nocovid_dir)\n",
    "\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "\n",
    "# Let's prepare a random input image from the training set.\n",
    "covid_img_files = [os.path.join(training_covid_dir, f) for f in training_covid_names]\n",
    "nocovid_img_files = [os.path.join(training_nocovid_dir, f) for f in training_nocovid_names]\n",
    "img_path = random.choice(covid_img_files + nocovid_img_files)\n",
    "#TD: Which one?\n",
    "print(\"Random file: \"+img_path)\n",
    "\n",
    "img = load_img(img_path, target_size=(324, 324))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (324, 324, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 324, 324, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "      x = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std()\n",
    "      x *= 64\n",
    "      x += 128\n",
    "      x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "#TD: Set \",cmap=\"gray\" \" here (refer to https://matplotlib.org/3.2.1/tutorials/colors/colormaps.html) but also preprocess the incoming data in monochromize()\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='gray') #cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mFZDVnIHxWA"
   },
   "source": [
    "# Display Loss/Accuracy graphs to spot possible overfitting and estimated epochs for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "colab_type": "code",
    "id": "G8EPXe0-ICW4",
    "outputId": "ff902d0d-79c6-459d-cd50-78c7809d6c18"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy using '+ptm)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss using '+ptm)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj1t5qMbHw_a"
   },
   "source": [
    "# Github repository dataset related cells - not needed for Waterkant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ko6qO8ByIQZ6"
   },
   "outputs": [],
   "source": [
    "#!pip install -q xlrd\n",
    "#!git clone https://github.com/ieee8023/covid-chestxray-dataset\n",
    "#TD Anstelle von dem oberen, dieses hier:\n",
    "if not os.path.exists(\"covid-chestxray-dataset\"):\n",
    "    !git clone https://github.com/ieee8023/covid-chestxray-dataset covid-chestxray-dataset\n",
    "else:\n",
    "     !git -C covid-chestxray-dataset fetch --all\n",
    "     !git -C covid-chestxray-dataset reset --hard origin/master\n",
    "\n",
    "!ls covid-chestxray-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZqqlz8lQDrY"
   },
   "outputs": [],
   "source": [
    "#TD Do not execute this if you do waterkand20 contest!!!\n",
    "\n",
    "data_list = pd.read_csv('covid-chestxray-dataset/metadata.csv')\n",
    "\n",
    "#Copy into source folders\n",
    "data_dir = 'covid-chestxray-dataset/images'\n",
    "rows = data_list.patientid \n",
    "n = len(rows)\n",
    "for i in range(1,n):\n",
    "#TD: Replaced by regex if data_list.loc[i, 'view'] == ('PA' or 'AP'): ... Now also accepting AP Suppinge, for example...\n",
    "  if re.match(r\"^PA|^AP\",data_list.loc[i, 'view']):\n",
    "    if data_list.loc[i, 'finding'] == ('COVID-19'): \n",
    "      FROM = os.path.join(data_dir, data_list.loc[i, 'filename'])\n",
    "      TO = os.path.join(source_covid, data_list.loc[i, 'filename'])\n",
    "#TD We monochromize the images and also specifically check for \"hadcolor\" and \"nodpi\". The files are saved as <name>_monochromized.tif\n",
    "      copyfileMonochromized(FROM,TO)\n",
    "#        copyfile(FROM,TO)    if data_list.loc[i, 'finding'] == ('No Finding'):\n",
    "    if data_list.loc[i, 'finding'] == ('No Finding'):\n",
    "      FROM = os.path.join(data_dir, data_list.loc[i, 'filename'])\n",
    "      TO = os.path.join(source_nocovid, data_list.loc[i, 'filename'])\n",
    "#TD We monochromize the images and also specifically check for \"hadcolor\" and \"nodpi\". The files are saved as <name>_monochromized.tif\n",
    "      copyfileMonochromized(FROM,TO)\n",
    "#        copyfile(FROM,TO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOLa_EJVelAi"
   },
   "outputs": [],
   "source": [
    "#Define a dataset splitting function\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    source_list = os.listdir(SOURCE)\n",
    "    for entry in source_list:\n",
    "        if (os.path.exists(os.path.join(SOURCE, entry))):\n",
    "            if (os.path.getsize((os.path.join(SOURCE,entry)) == 0)):\n",
    "                print('% is zero length, so ignoring' %entry)\n",
    "                source_list.remove(entry)\n",
    "                \n",
    "    source_list = random.sample(source_list, len(source_list))\n",
    "    \n",
    "    split_point = int(len(source_list) * SPLIT_SIZE)\n",
    "    training_list = source_list[:split_point]\n",
    "    testing_list = source_list[split_point:]\n",
    "\n",
    "    for entry in training_list:\n",
    "        FROM = os.path.join(SOURCE, entry)\n",
    "        TO = os.path.join(TRAINING, entry)\n",
    "        copyfile(FROM,TO)\n",
    "\n",
    "    for entry in testing_list:\n",
    "        FROM = os.path.join(SOURCE, entry)\n",
    "        TO = os.path.join(TESTING, entry)\n",
    "        print(FROM+\"-->\"+TO)\n",
    "        copyfile(FROM,TO)\n",
    "\n",
    "\n",
    "#Split the data into the representing sets in a certain ratio\n",
    "#split_size = .6\n",
    "#split_data(source_covid, training_covid_dir, testing_covid_dir, split_size)\n",
    "#split_data(source_nocovid, training_nocovid_dir, testing_nocovid_dir, split_size)  \n",
    "\n",
    "## KK\n",
    "#print('training_covid: ', len(training_covid_dir), ' testing_covid: ', len(testing_covid_dir))\n",
    "#print('training_nocovid: ', len(training_nocovid_dir), ' testing_nocovid: ', len(testing_nocovid_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mveGcIdq76_q"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "7UBYUy1h9w67",
    "outputId": "62812bb0-e847-480f-bcc5-b7233b6ec52b"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr=0.00001 # Learning rate # Adjusted by VD on 3.6.2020\n",
    "dr=0.4 # Dropout rate\n",
    "        \n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(324, 324, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Dropout(dr),  \n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dr), \\n\",\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "        ])\n",
    "        \n",
    "        \n",
    "        \n",
    "model.compile(optimizer=RMSprop(lr), loss='binary_crossentropy', metrics=['acc'])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVKwk--vXWU6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "def vgg_1(shape_in):\n",
    "    base_vgg_model = VGG16(include_top = True, input_shape = shape_in, weights ='imagenet')\n",
    "    \n",
    "    last_layer = base_vgg_model.layers[-2].output\n",
    "    \n",
    "    x = keras.layers.Dropout(0.2, name='dropout_1_0.2')(last_layer)\n",
    "    x = keras.layers.Dense(1024, activation='relu', name='my_dense_1')(last_layer)\n",
    "    x = keras.layers.Dropout(0.2, name='dropout_2_0.2')(x)\n",
    "    x = keras.layers.Dense(256, activation='relu', name='my_dense_2')(x)\n",
    "    x = keras.layers.Dropout(0.2, name='dropout_3_0.2')(x)\n",
    "    my_output = keras.layers.Dense(3, activation='softmax', name='my_dense_3')(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=base_vgg_model.inputs, outputs=my_output, name='VGG16_1 ')\n",
    "    \n",
    "    for layer in base_vgg_model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.summary()\n",
    "     \n",
    "    return model\n",
    "\n",
    "  \n",
    "\n",
    "def resnet(shape_in):\n",
    "    base_resnet_model = ResNet50(include_top = True, input_shape = shape_in, weights ='imagenet')\n",
    "\n",
    "    last_layer = base_resnet_model.layers[-2].output\n",
    "    \n",
    "    my_output = keras.layers.Dense(3, activation='softmax', name='my_dense')(last_layer)\n",
    "    \n",
    "    model = keras.models.Model(inputs=base_resnet_model.inputs, outputs=my_output, name='ResNet50 ')\n",
    "\n",
    "    for layer in base_resnet_model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Xidivocx.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyORpg6xd6TSzAMWtrs2nIQt",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}